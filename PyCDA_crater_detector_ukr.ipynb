{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aefafd18",
   "metadata": {},
   "source": [
    "### **Автоматизована детекція вирв з супутникових зображень: підготовка зображень та застосування PyCDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84699511",
   "metadata": {},
   "source": [
    "### Логіка побудови модулю CraterDetectionProcessor\n",
    "\n",
    "Розроблений продукт побудований за функціонально модульною структурою, яка дозволяє проводити комплексне обстеження територій та використовувати результати збору зображень з уражених територій\n",
    "Нижче наведено функціональні блоки (модулі), які забезпечують такий комплексний аналіз.\n",
    "\n",
    "#### 1. Блок витягання метаданих (extract_tile_metadata)\n",
    "* __Призначення:__ Розпізнавання та витягання географічних координат, масштабу та інших параметрів з імен файлів тайлів.\n",
    "* __Підтримувані формати імен файлів:__\n",
    "    - tile_001_50.450123_30.523456.png\n",
    "    - tile_50.450123_30.523456_15.png\n",
    "    - 512_256_50.450123_30.523456_15.png\n",
    "\n",
    "**Альтернативні підходи обробки метаданих:**\n",
    "- Читання з супровідних JSON/XML файлів\n",
    "- EXIF-дані: Витягання геоприв'язки з EXIF зображення\n",
    "- World files: Використання .world файлів для геопросторової прив'язки\n",
    "\n",
    "#### 2. Блок розрахунку роздільної здатності (calculate_resolution)\n",
    "* __Призначення:__ Перетворення пікселевих вимірів у метричні на основі рівня масштабу та географічного положення.\n",
    "* __Формула:__ `Resolution = (156543.03392 * cos(latitude)) / (2^zoom_level)`\n",
    "\n",
    "**Альтернативні методи:**\n",
    "- Haversine formula: Більш точні розрахунки для великих відстаней\n",
    "- UTM проекція: Використання UTM координат для локальних областей\n",
    "- Калібровка по еталонам: Використання відомих об'єктів для калібрування\n",
    "\n",
    "##### 3. Блок підготовки зображень (prepare_image)\n",
    "* __Призначення:__ Підвищення контрасту та різкості для покращення якості виявлення кратерів.\n",
    "* __Доступні методи підготовки:__\n",
    "    - adaptive (Рекомендований) - Комбінований підхід який послідовно застосовує до зображення різні перетворення. При цьому підтримуються наступні методи \n",
    "* __Нормалізація гістограми__ - CLAHE (Contrast Limited Adaptive Histogram Equalization). Забезпечує підвищення різкості, покращує локальний контраст без надмірного підсилення шумів. Ідеальний для зображень з нерівномірним освітленням\n",
    "Параметри: `clipLimit=3.0, tileGridSize=(8,8)`\n",
    "* __histogram__ - Швидкий, простий у реалізації, але може призводити до втрати деталей у темних/світлих областях. Рекомендовано до застосування для зображеннь з рівномірним освітленням\n",
    "* __unsharp__ - забезпечує підвищення різкості методом нерізкого маскування. Формула: `Enhanced = Original * 1.5 - GaussianBlur * 0.5`\n",
    "Застосування: Розмиті зображення, потреба у підкресленні країв\n",
    "* __morphology__ - Послідовно застосовуються фільтри $Opening + Closing$ з еліптичним ядром. Дозволяє виділти кругові структури, зменшує шум Рекомендовано до застосування для зображеннь з багатьма дрібними деталями\n",
    "\n",
    "**Альтернативні методи OpenCV:**\n",
    " - Білатеральна фільтрація (зберігає краї)\n",
    "\n",
    "    `bilateral = cv2.bilateralFilter(image, 9, 75, 75)`\n",
    "\n",
    " - Gamma корекція\n",
    "```\n",
    "    gamma = 1.2\n",
    "    gamma_corrected = np.power(image/255.0, gamma) * 255\n",
    "```\n",
    "\n",
    " - Топ-хет трансформація (виділення світлих об'єктів)\n",
    " ```\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15,15))\n",
    "    tophat = cv2.morphologyEx(image, cv2.MORPH_TOPHAT, kernel)\n",
    "```\n",
    " - Laplacian of Gaussian (LoG) для виділення країв\n",
    "```\n",
    "    gaussian = cv2.GaussianBlur(image, (5,5), 1.4)\n",
    "    log = cv2.Laplacian(gaussian, cv2.CV_64F)\n",
    "```\n",
    " - Difference of Gaussians (DoG)\n",
    " ```\n",
    "    blur1 = cv2.GaussianBlur(image, (5,5), 1.0)\n",
    "    blur2 = cv2.GaussianBlur(image, (5,5), 2.0)\n",
    "    dog = blur2 - blur1\n",
    "```\n",
    "\n",
    "#### 4. Блок виявлення кратерів (detect_craters)\n",
    "\n",
    "__Призначення:__ Використання моделі PyCDA для виявлення кратерів на підготовленому зображенні.\n",
    "__Основні кроки:__\n",
    "    - Ініціалізація детектора CDA(detector='unet')\n",
    "    - Прогнозування координат кратерів\n",
    "    - Нормалізація результатів у стандартний формат\n",
    "    - Сортування за розміром діаметру\n",
    "\n",
    "\n",
    "**Альтернативні підходи до виявлення кратерів:**\n",
    "Класичні методи ComputerVision:\n",
    "- Hough Transform для виявлення кіл\n",
    "```\n",
    "        circles = cv2.HoughCircles(image, cv2.HOUGH_GRADIENT, 1, 20,\n",
    "                          param1=50, param2=30, minRadius=10, maxRadius=100)\n",
    "```\n",
    "- Template matching з круговими шаблонами\n",
    "```\n",
    "    template = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (30,30))\n",
    "    result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)\n",
    "```\n",
    "- Контурний аналіз\n",
    "```\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    circular_contours = [c for c in contours if cv2.contourArea(c) > 100]\n",
    "```\n",
    " - Глибоке навчання:\n",
    "* YOLO: Для швидкого виявлення об'єктів\n",
    "* R-CNN: Для точного виявлення з класифікацією\n",
    "* U-Net: Семантична сегментація (використовується в PyCDA)\n",
    "    \n",
    "\n",
    "#### 5. Блок перетворення координат (pixels_to_geographic)\n",
    "* __Призначення:__ Перетворення пікселевих координат у географічні координати WGS84 та метричні розміри.\n",
    "* __Процес перетворення:__\n",
    "    - Розрахунок зміщення від центру тайлу\n",
    "    - Перетворення у метри\n",
    "    - Перетворення у географічні координати:\n",
    "\n",
    "**Альтернативні системи координат:**\n",
    "- UTM координати (більш точні для локальних областей)\n",
    "- Gauss-Kruger (для України)\n",
    " ```\n",
    "        gk_transformer = pyproj.Transformer.from_crs(\"EPSG:4326\", \"EPSG:28408\")\n",
    "        gk_x, gk_y = gk_transformer.transform(latitude, longitude)\n",
    "```\n",
    "\n",
    "#### 6. Блок збереження результатів (save_results)\n",
    "Підтримувані формати: CSV, JSON, GeoJSON - Стандарт для геопросторових даних\n",
    "Застосування: QGIS, ArcGIS, веб-карти (Leaflet, OpenLayers)\n",
    "Структура:\n",
    "```\n",
    "json{\n",
    "  \"type\": \"FeatureCollection\",\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"type\": \"Feature\",\n",
    "      \"geometry\": {\"type\": \"Point\", \"coordinates\": [lon, lat]},\n",
    "      \"properties\": {\"diameter_meters\": 25.5, \"area_sq_meters\": 510.7}\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "**Альтернативні формати:**\n",
    "- Shapefile для ГІС\n",
    "```\n",
    "    import geopandas as gpd\n",
    "    gdf = gpd.GeoDataFrame(results_df, \n",
    "                       geometry=gpd.points_from_xy(results_df.longitude, \n",
    "                                                   results_df.latitude))\n",
    "    gdf.to_file(\"craters.shp\")\n",
    "```\n",
    "\n",
    "- KML для Google Earth\n",
    "```\n",
    "    import simplekml\n",
    "    kml = simplekml.Kml()\n",
    "    for _, row in results_df.iterrows():\n",
    "        kml.newpoint(name=f\"Crater {row.name}\", coords=[(row.longitude, row.latitude)])\n",
    "```\n",
    "- PostGIS Database\n",
    "```\n",
    "    import sqlalchemy\n",
    "    engine = sqlalchemy.create_engine('postgresql://user:pass@host:port/dbname')\n",
    "    results_df.to_sql('craters', engine, if_exists='append', index=False)\n",
    "```\n",
    "\n",
    "#### 7. Інтеграція з SatelliteImageRetriever\n",
    "Спільне використання методів геоперетворення\n",
    "```\n",
    "from satellite_image_retriever import SatelliteImageRetriever\n",
    "\n",
    "retriever = SatelliteImageRetriever(\"API_KEY\", zoom=15)\n",
    "processor = CraterDetectionProcessor(\"tiles\", \"results\")\n",
    "\n",
    "pixel_coords = retriever.lat_lon_to_pixels(lat, lon, zoom)\n",
    "geo_coords = retriever.pixels_to_lat_lon(px, py, zoom)\n",
    "```\n",
    "\n",
    "Таким чином цей підхід забезпечує повний цикл обробки від супутникових знімків до геопросторових даних про кратери з можливістю подальшого аналізу в ГІС-системах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d503f1",
   "metadata": {},
   "source": [
    "<font color='darkred'>**N.B.**</font>\n",
    "У новіших версіях Keras (починаючи з 2.3.0 і особливо в Keras 3):\n",
    "* Параметр `lr` спочатку був застарілим (deprecated) і видавав попередження.\n",
    "* У Keras 3 він був повністю видалений і замінений на `learning_rate`.\n",
    "* Параметр `decay` також більше не підтримується в новій версі.\n",
    "\n",
    "Несумінсність версій PyCDA та TensorFlow/Keras викликає критичну <font color='darkred'>**помилку** `Argument(s) not recognized: {'lr': 0.009999999776482582}`.\n",
    "\n",
    "___Python 3.6___ - це єдина підтримувана версія.</font> PyCDA наразі не тестувався з іншими версіями Python, тому використання Python 3.8 і більше може призвести до проблем із сумісністю. \n",
    "\n",
    "При цьому Native Python 3.6 для macOS Apple Silicon (ARM64) не доступний (Check available Python versions: `conda search python --channel conda-forge`). Підтримка Python 3.6 завершилася у грудні 2021 року.\n",
    "\n",
    "#### Варіант для Apple Silicon (M1/M2) - емуляція x86_64\n",
    "```\n",
    "# Створіть порожнє середовище\n",
    "conda create -n cda_env\n",
    "\n",
    "# Активуйте його\n",
    "conda activate cda_env\n",
    "\n",
    "# Налаштуйте для x86_64\n",
    "conda config --env --set subdir osx-64\n",
    "\n",
    "# Встановіть Python 3.6\n",
    "conda install python=3.6\n",
    "\n",
    "# Перевірте, яка версія Python встановлена\n",
    "python --version\n",
    "\n",
    "# Оновіть pip\n",
    "python -m pip install --upgrade pip\n",
    "\n",
    "# Встановіть numpy першим (обов'язково!)\n",
    "pip install numpy\n",
    "\n",
    "# Встановіть PyCDA\n",
    "pip install pycda\n",
    "\n",
    "# Встановіть пакети\n",
    "conda install ipykernel -y\n",
    "pip install opencv-python==4.5.1.48 \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee0e1ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import re\n",
    "import math\n",
    "from PIL import Image\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab48313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Налаштування логування\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c734b2",
   "metadata": {},
   "source": [
    "### Основний клас який реалізує логіку детекції кратерів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CraterDetectionProcessor:\n",
    "    \"\"\"\n",
    "    Клас для аналізу кратерів на супутникових зображеннях з використанням PyCDA\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tiles_directory: str, output_directory: str = \"crater_analysis\"):\n",
    "        \"\"\"\n",
    "        Ініціалізація процесора для аналізу кратерів.\n",
    "        \n",
    "        Args:\n",
    "            tiles_directory: Папка з тайлами від SatelliteImageRetriever\n",
    "            output_directory: Папка для збереження результатів\n",
    "        \"\"\"\n",
    "        self.tiles_directory = Path(tiles_directory)\n",
    "        self.output_directory = Path(output_directory)\n",
    "        self.output_directory.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Результати аналізу\n",
    "        self.all_detections = []\n",
    "        self.processed_tiles = []\n",
    "        \n",
    "        # Параметри для підготовки зображень\n",
    "        self.contrast_kernels = {\n",
    "            'sobel_x': np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]),\n",
    "            'sobel_y': np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]),\n",
    "            'laplacian': np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]]),\n",
    "            'sharpen': np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]),\n",
    "            'edge_enhance': np.array([[0, -1, 0], [-1, 4, -1], [0, -1, 0]])\n",
    "        }\n",
    "        \n",
    "    def extract_tile_metadata(self, filename: str) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Витягує метадані з імені файлу тайлу.\n",
    "        \n",
    "        Очікуваний формат: tile_001_50.450123_30.523456.png\n",
    "        або tile_lat_lon_zoom.png\n",
    "        \n",
    "        Args:\n",
    "            filename: Ім'я файлу тайлу\n",
    "            \n",
    "        Returns:\n",
    "            Словник з метаданими або None якщо не вдалося розпарсити\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Паттерн для розпізнавання різних форматів імен файлів\n",
    "            patterns = [\n",
    "                r'tile_(\\d+)_(-?\\d+\\.\\d+)_(-?\\d+\\.\\d+)\\.png',  # tile_001_lat_lon.png\n",
    "                r'tile_(-?\\d+\\.\\d+)_(-?\\d+\\.\\d+)_(\\d+)\\.png',   # tile_lat_lon_zoom.png\n",
    "                r'(\\d+)_(\\d+)_(-?\\d+\\.\\d+)_(-?\\d+\\.\\d+)_(\\d+)\\.png'  # x_y_lat_lon_zoom.png\n",
    "            ]\n",
    "            \n",
    "            for pattern in patterns:\n",
    "                match = re.match(pattern, filename)\n",
    "                if match:\n",
    "                    groups = match.groups()\n",
    "                    if len(groups) == 3:\n",
    "                        # tile_001_lat_lon.png або tile_lat_lon_zoom.png\n",
    "                        if '.' in groups[0]:\n",
    "                            return {\n",
    "                                'latitude': float(groups[0]),\n",
    "                                'longitude': float(groups[1]),\n",
    "                                'zoom': int(groups[2]) if groups[2].isdigit() else 15,\n",
    "                                'tile_id': filename\n",
    "                            }\n",
    "                        else:\n",
    "                            return {\n",
    "                                'tile_index': int(groups[0]),\n",
    "                                'latitude': float(groups[1]),\n",
    "                                'longitude': float(groups[2]),\n",
    "                                'zoom': 15,  # значення за замовчуванням\n",
    "                                'tile_id': filename\n",
    "                            }\n",
    "                    elif len(groups) == 5:\n",
    "                        # x_y_lat_lon_zoom.png\n",
    "                        return {\n",
    "                            'tile_x': int(groups[0]),\n",
    "                            'tile_y': int(groups[1]),\n",
    "                            'latitude': float(groups[2]),\n",
    "                            'longitude': float(groups[3]),\n",
    "                            'zoom': int(groups[4]),\n",
    "                            'tile_id': filename\n",
    "                        }\n",
    "            \n",
    "            logger.warning(f\"Не вдалося розпарсити метадані з файлу: {filename}\")\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Помилка при розборі метаданих {filename}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_resolution(self, zoom_level: int, latitude: float) -> float:\n",
    "        \"\"\"\n",
    "        Розраховує роздільну здатність зображення в метрах на піксель.\n",
    "        \n",
    "        Args:\n",
    "            zoom_level: Рівень масштабу карти\n",
    "            latitude: Широта (для корекції спотворень проекції)\n",
    "            \n",
    "        Returns:\n",
    "            Роздільна здатність в метрах/піксель\n",
    "        \"\"\"\n",
    "        # Базова роздільна здатність на екваторі для zoom=0\n",
    "        base_resolution = 156543.03392  # метрів/піксель на zoom=0\n",
    "        \n",
    "        # Корекція для широти (Web Mercator проекція)\n",
    "        lat_correction = math.cos(math.radians(latitude))\n",
    "        \n",
    "        # Роздільна здатність для заданого рівня масштабу\n",
    "        resolution = (base_resolution * lat_correction) / (2 ** zoom_level)\n",
    "        \n",
    "        return resolution\n",
    "    \n",
    "    def prepare_image(self, image: np.ndarray, method: str = 'adaptive') -> np.ndarray:\n",
    "        \n",
    "        \"\"\"\n",
    "        Підготовка зображення для аналізу кратерів.\n",
    "        \n",
    "        Args:\n",
    "            image: Вхідне зображення\n",
    "            method: Метод підготовки ('adaptive', 'clahe', 'histogram', 'unsharp')\n",
    "            \n",
    "        Returns:\n",
    "            Підготовлене зображення\n",
    "        \"\"\"\n",
    "\n",
    "        # Перетворення у градації сірого якщо потрібно\n",
    "        if len(image.shape) == 3:\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = image.copy()\n",
    "        \n",
    "        if method == 'adaptive':\n",
    "            # Адаптивний метод з комбінацією технік\n",
    "            \n",
    "            # 1. Нормалізація гістограми\n",
    "            normalized = cv2.equalizeHist(gray)\n",
    "            \n",
    "            # 2. CLAHE для локального покращення контрасту\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            enhanced = clahe.apply(normalized)\n",
    "            \n",
    "            # 3. Підвищення різкості\n",
    "            sharpened = cv2.filter2D(enhanced, -1, self.contrast_kernels['sharpen'])\n",
    "            \n",
    "            return sharpened\n",
    "            \n",
    "        elif method == 'clahe':\n",
    "            # Контрастно-адаптивна еквалізація гістограми\n",
    "            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "            return clahe.apply(gray)\n",
    "            \n",
    "        elif method == 'histogram':\n",
    "            # Проста еквалізація гістограми\n",
    "            return cv2.equalizeHist(gray)\n",
    "            \n",
    "        elif method == 'unsharp':\n",
    "            # Unsharp masking для підвищення різкості\n",
    "            gaussian = cv2.GaussianBlur(gray, (0,0), 2.0)\n",
    "            unsharp = cv2.addWeighted(gray, 1.5, gaussian, -0.5, 0)\n",
    "            return unsharp\n",
    "            \n",
    "        elif method == 'morphology':\n",
    "            # Морфологічні операції для виділення структур\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "            opened = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n",
    "            return cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "            \n",
    "        else:\n",
    "            logger.warning(f\"Невідомий метод підготовки: {method}. Використовую 'adaptive'\")\n",
    "            return self.prepare_image(image, 'adaptive')\n",
    "    \n",
    "    def detect_craters(self, image: np.ndarray, tile_metadata: Dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Виявлення кратерів на підготовленому зображенні.\n",
    "        \n",
    "        Args:\n",
    "            image: Підготовлене зображення\n",
    "            tile_metadata: Метадані тайлу\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame з координатами кратерів у пікселях\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Імпорт PyCDA\n",
    "            from pycda import CDA\n",
    "            \n",
    "            # Ініціалізація детектора\n",
    "            cda = CDA(detector='unet')\n",
    "            \n",
    "            # Виявлення кратерів\n",
    "            detections = cda.predict(image)\n",
    "            \n",
    "            # Отримання детального прогнозу\n",
    "            prediction = cda.get_prediction(image, verbose=False)\n",
    "            \n",
    "            # Якщо detections порожній, повертаємо порожній DataFrame\n",
    "            if detections is None or len(detections) == 0:\n",
    "                return pd.DataFrame(columns=['pixel_x', 'pixel_y', 'diameter_pixels'])\n",
    "            \n",
    "            # Перетворення результатів у DataFrame\n",
    "            if isinstance(detections, pd.DataFrame):\n",
    "                \n",
    "                df = detections.copy()\n",
    "                # Переіменування колонок для уніфікації\n",
    "                if 'lat' in df.columns and 'lon' in df.columns:\n",
    "                    df = df.rename(columns={'lat': 'pixel_y', 'lon': 'pixel_x'})\n",
    "                elif 'y' in df.columns and 'x' in df.columns:\n",
    "                    df = df.rename(columns={'y': 'pixel_y', 'x': 'pixel_x'})\n",
    "            else:\n",
    "                # Якщо інший формат, намагаємося конвертувати\n",
    "                df = pd.DataFrame(detections)\n",
    "            \n",
    "            # Переконаємося що є необхідні колонки\n",
    "            required_columns = ['pixel_x', 'pixel_y', 'diameter_pixels']\n",
    "            for col in required_columns:\n",
    "                if col not in df.columns:\n",
    "                    if col == 'diameter_pixels' and 'diameter' in df.columns:\n",
    "                        df['diameter_pixels'] = df['diameter']\n",
    "                    else:\n",
    "                        logger.warning(f\"Відсутня колонка {col} в результатах детекції\")\n",
    "                        return pd.DataFrame(columns=required_columns)\n",
    "            \n",
    "            # Сортування за діаметром\n",
    "            df = df.sort_values(by=['diameter_pixels'], ascending=False)\n",
    "            \n",
    "            # Додавання метаданих тайлу\n",
    "            for key, value in tile_metadata.items():\n",
    "                df[f'tile_{key}'] = value\n",
    "            \n",
    "            logger.info(f\"Виявлено {len(df)} кратерів на тайлі {tile_metadata.get('tile_id', 'unknown')}\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except ImportError:\n",
    "            logger.error(\"PyCDA не встановлено\")\n",
    "            # Заглушка для тестування без PyCDA\n",
    "            return self._mock_crater_detection(image, tile_metadata)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Помилка при виявленні кратерів: {e}\")\n",
    "            return pd.DataFrame(columns=['pixel_x', 'pixel_y', 'diameter_pixels'])\n",
    "    \n",
    "    def _mock_crater_detection(self, image: np.ndarray, tile_metadata: Dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Заглушка для демонстрації без PyCDA.\n",
    "        Генерує випадкові координати кратерів для тестування.\n",
    "        \"\"\"\n",
    "        np.random.seed(42)  # Для відтворюваності\n",
    "        \n",
    "        # Генеруємо 3-7 випадкових кратерів\n",
    "        n_craters = np.random.randint(3, 8)\n",
    "        h, w = image.shape\n",
    "        \n",
    "        data = []\n",
    "        for i in range(n_craters):\n",
    "            x = np.random.randint(50, w-50)\n",
    "            y = np.random.randint(50, h-50)\n",
    "            diameter = np.random.uniform(15, 40)\n",
    "            \n",
    "            data.append({\n",
    "                'pixel_x': x,\n",
    "                'pixel_y': y,\n",
    "                'diameter_pixels': diameter\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.sort_values(by=['diameter_pixels'], ascending=False)\n",
    "        \n",
    "        # Додавання метаданих тайлу\n",
    "        for key, value in tile_metadata.items():\n",
    "            df[f'tile_{key}'] = value\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def pixels_to_geographic(self, detections_df: pd.DataFrame, \n",
    "                           tile_center_lat: float, tile_center_lon: float,\n",
    "                           zoom_level: int, image_size: Tuple[int, int] = (640, 640)) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Перетворення пікселевих координат у географічні координати та метричні розміри.\n",
    "        \n",
    "        Args:\n",
    "            detections_df: DataFrame з виявленими кратерами в пікселях\n",
    "            tile_center_lat: Широта центру тайлу\n",
    "            tile_center_lon: Довгота центру тайлу\n",
    "            zoom_level: Рівень масштабу\n",
    "            image_size: Розмір зображення в пікселях (ширина, висота)\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame з географічними координатами та метричними розмірами\n",
    "        \"\"\"\n",
    "        if detections_df.empty:\n",
    "            return detections_df\n",
    "        \n",
    "        result_df = detections_df.copy()\n",
    "        \n",
    "        # Розрахунок роздільної здатності\n",
    "        resolution = self.calculate_resolution(zoom_level, tile_center_lat)\n",
    "        \n",
    "        # Розмір зображення\n",
    "        img_width, img_height = image_size\n",
    "        center_x, center_y = img_width // 2, img_height // 2\n",
    "        \n",
    "        # Перетворення пікселевих координат у відносні зміщення\n",
    "        pixel_x = result_df['pixel_x'].values\n",
    "        pixel_y = result_df['pixel_y'].values\n",
    "        \n",
    "        # Зміщення від центру в пікселях\n",
    "        dx_pixels = pixel_x - center_x\n",
    "        dy_pixels = pixel_y - center_y  # Y збільшується вниз\n",
    "        \n",
    "        # Зміщення в метрах\n",
    "        dx_meters = dx_pixels * resolution\n",
    "        dy_meters = -dy_pixels * resolution  # Інвертуємо Y (північ = позитивний)\n",
    "        \n",
    "        # Константи для перетворення метрів у градуси\n",
    "        METERS_PER_DEGREE_LAT = 111320  # приблизно постійна\n",
    "        meters_per_degree_lon = METERS_PER_DEGREE_LAT * math.cos(math.radians(tile_center_lat))\n",
    "        \n",
    "        # Розрахунок географічних координат\n",
    "        result_df['latitude'] = tile_center_lat + (dy_meters / METERS_PER_DEGREE_LAT)\n",
    "        result_df['longitude'] = tile_center_lon + (dx_meters / meters_per_degree_lon)\n",
    "        \n",
    "        # Перетворення діаметру з пікселів у метри\n",
    "        result_df['diameter_meters'] = result_df['diameter_pixels'] * resolution\n",
    "        \n",
    "        # Розрахунок радіусу та площі\n",
    "        result_df['radius_meters'] = result_df['diameter_meters'] / 2\n",
    "        result_df['area_sq_meters'] = np.pi * (result_df['radius_meters'] ** 2)\n",
    "        \n",
    "        # Додавання технічних параметрів\n",
    "        result_df['resolution_m_per_pixel'] = resolution\n",
    "        result_df['zoom_level'] = zoom_level\n",
    "        \n",
    "        logger.info(f\"Перетворено {len(result_df)} кратерів у географічні координати\")\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def process_single_tile(self, tile_path: Path, \n",
    "                           preparation_method: str = 'adaptive') -> Optional[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Обробка одного тайлу: підготовка, виявлення кратерів, перетворення координат.\n",
    "        \n",
    "        Args:\n",
    "            tile_path: Шлях до файлу тайлу\n",
    "            preparation_method: Метод підготовки зображення\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame з результатами або None у разі помилки\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Витягання метаданих з імені файлу\n",
    "            metadata = self.extract_tile_metadata(tile_path.name)\n",
    "            if metadata is None:\n",
    "                logger.warning(f\"Пропускаю файл через відсутність метаданих: {tile_path.name}\")\n",
    "                return None\n",
    "            \n",
    "            # Завантаження зображення\n",
    "            image = cv2.imread(str(tile_path))\n",
    "            if image is None:\n",
    "                logger.error(f\"Не вдалося завантажити зображення: {tile_path}\")\n",
    "                return None\n",
    "            \n",
    "            # Підготовка зображення\n",
    "            prepared_image = self.prepare_image(image, preparation_method)\n",
    "            \n",
    "            # Збереження підготовленого зображення для контролю якості\n",
    "            prepared_path = self.output_directory / f\"prepared_{tile_path.stem}.png\"\n",
    "            cv2.imwrite(str(prepared_path), prepared_image)\n",
    "            \n",
    "            # Виявлення кратерів\n",
    "            detections = self.detect_craters(prepared_image, metadata)\n",
    "            \n",
    "            if detections.empty:\n",
    "                logger.info(f\"Кратери не виявлені на тайлі: {tile_path.name}\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "            # Перетворення у географічні координати\n",
    "            geographic_detections = self.pixels_to_geographic(\n",
    "                detections,\n",
    "                metadata['latitude'],\n",
    "                metadata['longitude'],\n",
    "                metadata.get('zoom', 15),\n",
    "                prepared_image.shape[:2][::-1]  # (width, height)\n",
    "            )\n",
    "            \n",
    "            # Додавання інформації про файл\n",
    "            geographic_detections['source_file'] = tile_path.name\n",
    "            geographic_detections['preparation_method'] = preparation_method\n",
    "            geographic_detections['processing_timestamp'] = pd.Timestamp.now()\n",
    "            \n",
    "            logger.info(f\"Успішно оброблено тайл {tile_path.name}: {len(geographic_detections)} кратерів\")\n",
    "            \n",
    "            return geographic_detections\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Помилка при обробці тайлу {tile_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def process_all_tiles(self, preparation_method: str = 'adaptive',\n",
    "                         file_pattern: str = \"*.png\") -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Обробка всіх тайлів у директорії.\n",
    "        \n",
    "        Args:\n",
    "            preparation_method: Метод підготовки зображень\n",
    "            file_pattern: Паттерн для пошуку файлів\n",
    "            \n",
    "        Returns:\n",
    "            Зведений DataFrame з усіма виявленими кратерами\n",
    "        \"\"\"\n",
    "        logger.info(f\"Початок обробки тайлів у директорії: {self.tiles_directory}\")\n",
    "        \n",
    "        # Пошук файлів тайлів\n",
    "        tile_files = list(self.tiles_directory.glob(file_pattern))\n",
    "        logger.info(f\"Знайдено {len(tile_files)} файлів тайлів\")\n",
    "        \n",
    "        if not tile_files:\n",
    "            logger.warning(\"Тайли не знайдені!\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        all_results = []\n",
    "        processed_count = 0\n",
    "        \n",
    "        for tile_path in tile_files:\n",
    "            logger.info(f\"Обробка тайлу {processed_count + 1}/{len(tile_files)}: {tile_path.name}\")\n",
    "            \n",
    "            result = self.process_single_tile(tile_path, preparation_method)\n",
    "            \n",
    "            if result is not None and not result.empty:\n",
    "                all_results.append(result)\n",
    "                self.processed_tiles.append(tile_path.name)\n",
    "            \n",
    "            processed_count += 1\n",
    "        \n",
    "        # Об'єднання всіх результатів\n",
    "        if all_results:\n",
    "            combined_results = pd.concat(all_results, ignore_index=True)\n",
    "            logger.info(f\"Загалом виявлено {len(combined_results)} кратерів на {len(all_results)} тайлах\")\n",
    "        else:\n",
    "            combined_results = pd.DataFrame()\n",
    "            logger.warning(\"Кратери не виявлені на жодному тайлі\")\n",
    "        \n",
    "        self.all_detections = combined_results\n",
    "        return combined_results\n",
    "    \n",
    "    def save_results(self, results_df: pd.DataFrame, \n",
    "                    formats: List[str] = ['csv', 'json', 'geojson']) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Збереження результатів у різних форматах.\n",
    "        \n",
    "        Args:\n",
    "            results_df: DataFrame з результатами\n",
    "            formats: Список форматів для збереження\n",
    "            \n",
    "        Returns:\n",
    "            Словник з шляхами до збережених файлів\n",
    "        \"\"\"\n",
    "        saved_files = {}\n",
    "        timestamp = pd.Timestamp.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        if results_df.empty:\n",
    "            logger.warning(\"Немає результатів для збереження\")\n",
    "            return saved_files\n",
    "        \n",
    "        try:\n",
    "            # CSV формат\n",
    "            if 'csv' in formats:\n",
    "                csv_path = self.output_directory / f\"crater_detections_{timestamp}.csv\"\n",
    "                results_df.to_csv(csv_path, index=False)\n",
    "                saved_files['csv'] = str(csv_path)\n",
    "                logger.info(f\"Збережено CSV: {csv_path}\")\n",
    "            \n",
    "            # JSON формат\n",
    "            if 'json' in formats:\n",
    "                json_path = self.output_directory / f\"crater_detections_{timestamp}.json\"\n",
    "                results_df.to_json(json_path, orient='records', indent=2)\n",
    "                saved_files['json'] = str(json_path)\n",
    "                logger.info(f\"Збережено JSON: {json_path}\")\n",
    "            \n",
    "            # GeoJSON формат для ГІС\n",
    "            if 'geojson' in formats:\n",
    "                geojson_path = self.output_directory / f\"crater_detections_{timestamp}.geojson\"\n",
    "                self._save_as_geojson(results_df, geojson_path)\n",
    "                saved_files['geojson'] = str(geojson_path)\n",
    "                logger.info(f\"Збережено GeoJSON: {geojson_path}\")\n",
    "            \n",
    "            # Метадані аналізу\n",
    "            metadata_path = self.output_directory / f\"analysis_metadata_{timestamp}.json\"\n",
    "            self._save_analysis_metadata(results_df, metadata_path)\n",
    "            saved_files['metadata'] = str(metadata_path)\n",
    "            \n",
    "            return saved_files\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Помилка при збереженні результатів: {e}\")\n",
    "            return saved_files\n",
    "    \n",
    "    def _save_as_geojson(self, results_df: pd.DataFrame, output_path: Path):\n",
    "        \"\"\"Збереження результатів у форматі GeoJSON.\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        for _, row in results_df.iterrows():\n",
    "            feature = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Point\",\n",
    "                    \"coordinates\": [row['longitude'], row['latitude']]\n",
    "                },\n",
    "                \"properties\": {\n",
    "                    \"diameter_meters\": float(row['diameter_meters']),\n",
    "                    \"area_sq_meters\": float(row['area_sq_meters']),\n",
    "                    \"source_file\": row['source_file'],\n",
    "                    \"zoom_level\": int(row['zoom_level']),\n",
    "                    \"resolution_m_per_pixel\": float(row['resolution_m_per_pixel'])\n",
    "                }\n",
    "            }\n",
    "            features.append(feature)\n",
    "        \n",
    "        geojson = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"features\": features\n",
    "        }\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(geojson, f, indent=2)\n",
    "    \n",
    "    def _save_analysis_metadata(self, results_df: pd.DataFrame, output_path: Path):\n",
    "        \"\"\"Збереження метаданих аналізу.\"\"\"\n",
    "        metadata = {\n",
    "            \"analysis_timestamp\": pd.Timestamp.now().isoformat(),\n",
    "            \"total_craters_detected\": len(results_df),\n",
    "            \"total_tiles_processed\": len(self.processed_tiles),\n",
    "            \"processed_tiles\": self.processed_tiles,\n",
    "            \"statistics\": {\n",
    "                \"min_diameter_meters\": float(results_df['diameter_meters'].min()) if not results_df.empty else 0,\n",
    "                \"max_diameter_meters\": float(results_df['diameter_meters'].max()) if not results_df.empty else 0,\n",
    "                \"mean_diameter_meters\": float(results_df['diameter_meters'].mean()) if not results_df.empty else 0,\n",
    "                \"total_area_sq_meters\": float(results_df['area_sq_meters'].sum()) if not results_df.empty else 0\n",
    "            },\n",
    "            \"bounding_box\": {\n",
    "                \"min_latitude\": float(results_df['latitude'].min()) if not results_df.empty else 0,\n",
    "                \"max_latitude\": float(results_df['latitude'].max()) if not results_df.empty else 0,\n",
    "                \"min_longitude\": float(results_df['longitude'].min()) if not results_df.empty else 0,\n",
    "                \"max_longitude\": float(results_df['longitude'].max()) if not results_df.empty else 0\n",
    "            } if not results_df.empty else {}\n",
    "        }\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863edc4",
   "metadata": {},
   "source": [
    "#### Основна функція входу та приклад запуску"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519da03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Приклад використання CraterDetectionProcessor.\n",
    "    \"\"\"\n",
    "    # Налаштування шляхів\n",
    "    tiles_directory = \"Data/satellite_tiles\"  # Папка з тайлами від SatelliteImageRetriever\n",
    "    output_directory = \"Data/crater_analysis_results\"\n",
    "    \n",
    "    # Створення процесора\n",
    "    processor = CraterDetectionProcessor(tiles_directory, output_directory)\n",
    "    \n",
    "    # Обробка всіх тайлів\n",
    "    results = processor.process_all_tiles(\n",
    "        preparation_method='adaptive',  # або 'clahe', 'histogram', 'unsharp'\n",
    "        file_pattern=\"*.png\"\n",
    "    )\n",
    "    \n",
    "    # Збереження результатів\n",
    "    if not results.empty:\n",
    "        saved_files = processor.save_results(\n",
    "            results, \n",
    "            formats=['csv', 'json', 'geojson']\n",
    "        )\n",
    "        \n",
    "        print(\"Аналіз завершено!\")\n",
    "        print(f\"Виявлено кратерів: {len(results)}\")\n",
    "        print(\"Збережені файли:\")\n",
    "        for format_type, filepath in saved_files.items():\n",
    "            print(f\"  {format_type.upper()}: {filepath}\")\n",
    "        \n",
    "        # Виведення статистики\n",
    "        if len(results) > 0:\n",
    "            print(f\"\\nСтатистика:\")\n",
    "            print(f\"  Середній діаметр: {results['diameter_meters'].mean():.2f} м\")\n",
    "            print(f\"  Максимальний діаметр: {results['diameter_meters'].max():.2f} м\")\n",
    "            print(f\"  Загальна площа кратерів: {results['area_sq_meters'].sum():.2f} м²\")\n",
    "    else:\n",
    "        print(\"Кратери не виявлені.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b67638",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f3d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections.sort_values(by=['diameter'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4833fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_and_plot(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219f2314",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
